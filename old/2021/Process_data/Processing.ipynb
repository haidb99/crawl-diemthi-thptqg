{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16c00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "Location_master = 'spark://linux:7077'\n",
    "Location_master = 'local'\n",
    "try:\n",
    "    sparkSession.stop()\n",
    "except:\n",
    "    pass\n",
    "sparkSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(Location_master)\\\n",
    "    .appName(\"Process 2020\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config('spark.cores.max','4')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce8a884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------+---------+------+-------+--------+-------+------+----+-------+\n",
      "|     SBD|Toan|Ngu_van|Ngoai_ngu|Vat_ly|Hoa_hoc|Sinh_hoc|Lich_su|Dia_ly|GDCD|Cum_thi|\n",
      "+--------+----+-------+---------+------+-------+--------+-------+------+----+-------+\n",
      "|02000096| 7.8|   5.75|     null|  7.75|   6.75|     5.5|   null|  null|null|     02|\n",
      "|02000095|   8|   null|     null|  null|   null|    null|   null|  null|null|     02|\n",
      "|02000094|   8|   6.75|      8.8|   5.5|   6.25|    7.25|   null|  null|null|     02|\n",
      "|02000092| 8.8|   6.75|        9|  8.75|   7.75|    3.25|   null|  null|null|     02|\n",
      "|02000091|   8|   5.75|      9.2|  8.75|   8.25|     5.5|   null|  null|null|     02|\n",
      "+--------+----+-------+---------+------+-------+--------+-------+------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- SBD: string (nullable = true)\n",
      " |-- Toan: string (nullable = true)\n",
      " |-- Ngu_van: string (nullable = true)\n",
      " |-- Ngoai_ngu: string (nullable = true)\n",
      " |-- Vat_ly: string (nullable = true)\n",
      " |-- Hoa_hoc: string (nullable = true)\n",
      " |-- Sinh_hoc: string (nullable = true)\n",
      " |-- Lich_su: string (nullable = true)\n",
      " |-- Dia_ly: string (nullable = true)\n",
      " |-- GDCD: string (nullable = true)\n",
      " |-- Cum_thi: string (nullable = true)\n",
      "\n",
      "1946845\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../../Data_process/*/*'\n",
    "data_all = sparkSession.read.csv(data_dir, header=True)\n",
    "\n",
    "data_all = data_all.drop('_c0', 'KHTN', 'KHXH', 'Cum_thi')\n",
    "data_all = data_all.withColumn('Cum_thi', f.substring(f.col('SBD'), 0, 2))\n",
    "data_all.show(5)\n",
    "data_all.printSchema()\n",
    "print(data_all.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d36ff",
   "metadata": {},
   "source": [
    "### Thay đổi kiểu dữ liệu các trường dữ liệu về đúng dạng của nó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc8a2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import FloatType, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "318db31e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SBD: string (nullable = true)\n",
      " |-- Toan: float (nullable = true)\n",
      " |-- Ngu_van: float (nullable = true)\n",
      " |-- Ngoai_ngu: float (nullable = true)\n",
      " |-- Vat_ly: float (nullable = true)\n",
      " |-- Hoa_hoc: float (nullable = true)\n",
      " |-- Sinh_hoc: float (nullable = true)\n",
      " |-- Lich_su: float (nullable = true)\n",
      " |-- Dia_ly: float (nullable = true)\n",
      " |-- GDCD: float (nullable = true)\n",
      " |-- Cum_thi: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_all = data_all.drop('_c0')\n",
    "data_all = data_all.withColumn('Toan', F.col('Toan').cast(FloatType()))\n",
    "data_all = data_all.withColumn('Ngu_van', F.col('Ngu_van').cast(FloatType()))\n",
    "data_all = data_all.withColumn('Ngoai_ngu', F.col('Ngoai_ngu').cast(FloatType()))\n",
    "data_all = data_all.withColumn('Vat_ly', F.col('Vat_ly').cast(FloatType()))\n",
    "data_all = data_all.withColumn('Hoa_hoc', F.col('Hoa_hoc').cast(FloatType()))\n",
    "data_all = data_all.withColumn('Sinh_hoc', F.col('Sinh_hoc').cast(FloatType()))\n",
    "data_all = data_all.withColumn('Lich_su', F.col('Lich_su').cast(FloatType()))\n",
    "data_all = data_all.withColumn('Dia_ly', F.col('Dia_ly').cast(FloatType()))\n",
    "data_all = data_all.withColumn('GDCD', F.col('GDCD').cast(FloatType()))\n",
    "data_all = data_all.withColumn('SBD', F.col('SBD').cast(StringType()))\n",
    "data_all = data_all.withColumn('Cum_thi', F.col('Cum_thi').cast(StringType()))\n",
    "\n",
    "data_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "521f647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_check = data_all.withColumn('crawl', f.substring(f.col('SBD'), 3, 4)).select('Cum_thi', 'crawl')\n",
    "data_check = data_check.groupBy('Cum_thi', 'crawl').count().orderBy('Cum_thi', 'crawl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "627f359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988013\n"
     ]
    }
   ],
   "source": [
    "data_all = data_all.drop_duplicates()\n",
    "print(data_all.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16ef1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "data_all = data_all.withColumn('row_num', f.row_number().over(\n",
    "    Window.partitionBy('SBD').orderBy('SBD')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baa3a9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+---------+------+-------+--------+-------+------+----+-------+-------+\n",
      "|SBD|Toan|Ngu_van|Ngoai_ngu|Vat_ly|Hoa_hoc|Sinh_hoc|Lich_su|Dia_ly|GDCD|Cum_thi|row_num|\n",
      "+---+----+-------+---------+------+-------+--------+-------+------+----+-------+-------+\n",
      "+---+----+-------+---------+------+-------+--------+-------+------+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_all.filter('row_num == 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8e7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(data_bosung.count() == 0):\n",
    "#     data_dup = data_all.filter('row_num = 2').withColumn('raw', f.substring(f.col('SBD'),0,5))\n",
    "#     data_dup = data_dup.groupBy('raw').count().toPandas()\n",
    "#     list_data_miss = []\n",
    "#     list_dup = list(data_dup['raw'].values)\n",
    "#     for dup in list_dup:\n",
    "#         for i in range(0,10):\n",
    "#             pattern = dup + str(i)\n",
    "#             if(data_all.filter(\"SBD like '{0}%'\".format(pattern)).count() == 0):\n",
    "#                 list_data_miss.append(pattern)\n",
    "\n",
    "#     list_data_miss = pd.DataFrame({'Miss': list_data_miss})\n",
    "#     list_data_miss.to_csv(\"../../../Data_process/ListMiss/miss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3affb72d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988013\n",
      "988013\n"
     ]
    }
   ],
   "source": [
    "print(data_all.count())\n",
    "data_all = data_all.filter('row_num == 1')\n",
    "data_all = data_all.drop(\"row_num\")\n",
    "data_all = data_all.drop_duplicates()\n",
    "print(data_all.count())\n",
    "data_all = data_all.orderBy(\"SBD\")\n",
    "data_all.repartition(1).write.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\").save(\"mydata.csv\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e446c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1cfb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
